# Progressive cross-modal semantic network for zero-shot sketch-based image retrieval

## Summary

<Summary: >The paper proposes a novel progressive cross-modal semantic network to improve the zero-shot retrieval performance of free-hand sketches and natural images by explicitly aligning projected features with their semantic features. The current methods lack explicit alignment which results in unsatisfactory retrieval performance.


## Target Task

Target: Computer Vision

## Content

<Abstract: >Zero-shot sketch-based image retrieval (ZS-SBIR) is a specific cross-modal retrieval task that involves searching natural images through the use of free-hand sketches under the zero-shot scenario. Most previous methods project the sketch and image features into a low-dimensional common space for efficient retrieval, and meantime align the projected features to their semantic features (e.g., category-level word vectors) in order to transfer knowledge from seen to unseen classes. However, the projection and alignment are always coupled; as a result, there is a lack of explicit alignment that consequently leads to unsatisfactory zero-shot retrieval performance. To address this issue, we propose a novel progressive cross-modal semantic network.



---

