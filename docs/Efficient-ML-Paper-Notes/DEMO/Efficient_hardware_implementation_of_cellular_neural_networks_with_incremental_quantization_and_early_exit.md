# Efficient hardware implementation of cellular neural networks with incremental quantization and early exit

## Summary

<Summary: >The proposed compressed Cellular neural network (CeNN) framework for FPGA implementation involves incremental quantization and early exit techniques. Incremental quantization reduces computation demands by quantizing CeNN templates to powers of two while maintaining acceptable performance. The experimental results show that the proposed framework achieves a speedup of up to 7.8x and 8.3x using incremental quantization and early exit techniques, respectively, with almost no performance loss compared to state-of-the-art implementations for four widely-adopted applications.


## Target Task

Target: FPGA implementation for efficient computation.

## Content

<Abstract: >In this paper, the authors propose a compressed Cellular neural network (CeNN) framework for efficient FPGA implementation, which involves various techniques such as incremental quantization and early exit. Incremental quantization quantizes the numbers in CeNN templates to powers of two, which reduces computation demands while maintaining acceptable performance. Experimental results on FPGAs show that incremental quantization and early exit can achieve a speedup of up to 7.8x and 8.3x, respectively, compared with the state-of-the-art implementations, while with almost no performance loss with four widely-adopted applications.



---

