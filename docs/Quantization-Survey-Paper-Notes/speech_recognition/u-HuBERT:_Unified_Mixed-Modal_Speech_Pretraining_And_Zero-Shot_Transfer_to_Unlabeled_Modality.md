# u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer to Unlabeled Modality

## Summary

<Summary: >The paper introduces u-HuBERT, a pre-training framework that uses both multimodal and unimodal speech with a common masked cluster prediction objective. The paper demonstrates that a single model with modality dropout during pre-training can perform better or similar to state-of-the-art modality-specific models. The fine-tuned model can also generalize well to different speech processing tasks, achieving zero-shot modality generalization for multiple speech processing tasks.


## Target Task

speech recognition

## Content

<Abstract: >In this paper, the authors present u-HuBERT, a self-supervised pre-training framework that can leverage both multimodal and unimodal speech with a unified masked cluster prediction objective. By utilizing modality dropout during pre-training, they demonstrate that a single fine-tuned model can achieve performance on par or better than the state-of-the-art modality-specific models. Moreover, their model fine-tuned only on audio can perform well with audio-visual and visual speech input, achieving zero-shot modality generalization for multiple speech processing tasks.



---

