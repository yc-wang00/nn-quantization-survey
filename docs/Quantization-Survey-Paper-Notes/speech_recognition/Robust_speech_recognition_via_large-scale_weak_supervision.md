# Robust speech recognition via large-scale weak supervision

## Summary

Summary: The paper discusses the study of speech processing systems that are trained to predict transcripts of audio on the internet, which resulted in models that generalize well and approach human-level accuracy and robustness, even in zero-shot transfer settings without fine-tuning. The researchers are releasing the models and inference code for further research on robust speech processing.


## Target Task

speech recognition

## Content

<Abstract: >
We study the capabilities of speech processing
systems trained simply to predict large amounts of
transcripts of audio on the internet. When scaled
to 680,000 hours of multilingual and multitask
supervision, the resulting models generalize well
to standard benchmarks and are often competitive
with prior fully supervised results but in a zero-
shot transfer setting without the need for any Ô¨Åne-
tuning. When compared to humans, the models
approach their accuracy and robustness. We are
releasing models and inference code to serve as
a foundation for further work on robust speech
processing.



---

