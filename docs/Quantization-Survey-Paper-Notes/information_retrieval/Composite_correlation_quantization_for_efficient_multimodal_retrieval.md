# Composite correlation quantization for efficient multimodal retrieval

## Summary

Summary: The proposed Composite Correlation Quantization (CCQ) model is designed for efficient similarity retrieval from large-scale multimodal databases. CCQ learns composite quantizers to convert the latent features into compact binary codes and preserves both intra-modal similarity and inter-modal correlation. The model outperforms state-of-the-art hashing methods for both unimodal and cross-modal retrieval.


## Target Task

information retrieval

## Content

<Abstract: > 
Efﬁcient similarity retrieval from large-scale multimodal databases is a challenging task faced by modern search engines and social networks. To retrieve semantically relevant results across heterogeneous data modalities, a system should enable cross-modal correlation and computation-efﬁcient indexing. In this paper, we propose Composite Correlation Quantization (CCQ), a novel model towards seamless multimodal hashing. CCQ jointly ﬁnds correlation-maximal mappings that transform different modalities into an isomorphic latent space and learns composite quantizers that convert the isomorphic latent features into compact binary codes. An optimization framework is devised to preserve both intra-modal similarity and inter-modal correlation through minimizing both reconstruction and quantization errors. CCQ outperforms state-of-the-art hashing methods for both unimodal and cross-modal retrieval.



---

