# Violet: End-to-end video-language transformers with masked visual-token modeling

## Summary

<Summary: >The paper presents VIOLET, a video-language Transformer model that utilizes a video transformer to model temporal dynamics and introduces a new pre-training task for better video modeling. VIOLET achieves state-of-the-art performance on 5 video question answering tasks and 4 text-to-video retrieval tasks.


## Target Task

nlp

## Content

<Abstract: >A great challenge in video-language (VidL) modeling lies in the disconnection between fixed video representations extracted from image/video understanding models and downstream VidL data. In this work, the authors present VIOLET, a fully end-to-end VIdeO-LanguagE Transformer, which adopts a video transformer to explicitly model the temporal dynamics of video inputs. They designed a new pre-training task, Masked Visual-token Modeling (MVM), for better video modeling. VIOLET achieves new state-of-the-art performance on 5 video question answering tasks and 4 text-to-video retrieval tasks.



---

