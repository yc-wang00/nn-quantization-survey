# Txt2Img-MHN: Remote sensing image generation from text using modern Hopfield networks

## Summary

Summary: The paper presents a new approach called Txt2Img-MHN for generating high-resolution remote sensing images from text descriptions. The approach involves hierarchical prototype learning on both text and image embeddings with modern Hopfield layers. The aim is to learn the most representative prototypes from text-image embeddings and achieve a coarse-to-fine learning strategy in generating images. The learned prototypes can represent complex semantics in text-to-image generation. Zero-shot classification was conducted on real remote sensing data to better evaluate the realism and semantic consistency of the generated images. The proposed approach demonstrated better results than existing methods in generating more realistic remote sensing images.


## Target Task

nlp

## Content

<Abstract: >The paper proposes a novel approach called Txt2Img-MHN for generating high-resolution remote sensing images based on text descriptions. The proposed method conducts hierarchical prototype learning on both text and image embeddings with modern Hopﬁeld layers. Instead of directly learning concrete but highly diverse text-image joint feature representations for different semantics, Txt2Img-MHN aims to learn the most representative prototypes from text-image embeddings, achieving a coarse-to-ﬁne learning strategy. The learned prototypes can then be utilized to represent more complex semantics in the text-to-image generation task. The paper also conducts zero-shot classification on real remote sensing data using the classification model trained on synthesized images for better evaluation of the realism and semantic consistency of the generated images. The experiments on the benchmark remote sensing text-image dataset demonstrate that the proposed Txt2Img-MHN can generate more realistic remote sensing images than existing methods.



---

