# Unitab: Unifying text and box outputs for grounded vision-language modeling

## Summary

Summary: UniTAB is proposed, a unified approach for grounded vision-language modeling that generates text and box outputs together while indicating word-box alignments in a shared token sequence, outperforming existing solutions in grounded captioning evaluations.


## Target Task

nlp

## Content

<Abstract: We propose UniTAB that Unifies Text And Box outputs for grounded vision-language (VL) modeling. To achieve this, models must generate desired text and box outputs together, and indicate the alignments between words and boxes. In contrast to existing solutions that use multiple separate modules for different outputs, UniTAB represents both text and box outputs with a shared token sequence, and introduces a special <obj> token to naturally indicate word-box alignments in the sequence. On grounded captioning, UniTAB presents a simpler solution with a single output head, and significantly outperforms state of the art in both grounding and captioning evaluations.>



---

