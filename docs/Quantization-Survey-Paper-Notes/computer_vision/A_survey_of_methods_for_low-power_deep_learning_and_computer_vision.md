# A survey of methods for low-power deep learning and computer vision

## Summary

Summary: The paper surveys the progress of low-power deep learning and computer vision, specifically in regards to inference, and discusses four major categories of techniques for compacting and accelerating DNN models: parameter quantization and pruning, compressed convolutional filters and matrix factorization, network architecture search, and knowledge distillation. The paper analyzes the advantages, disadvantages, and potential solutions to the problems with each method and proposes a set of evaluation metrics for future research.


## Target Task

computer vision

## Content

<Abstract: Deep neural networks (DNNs) require large amounts of parameters and operations, making them energy, computation, and memory intensive. Recent research has focused on reducing memory requirements, energy consumption, and the number of operations without sacrificing accuracy for low-power devices with limited compute resources. This paper surveys the progress of low-power deep learning and computer vision, specifically in regards to inference, and discusses four major categories of techniques for compacting and accelerating DNN models: parameter quantization and pruning, compressed convolutional filters and matrix factorization, network architecture search, and knowledge distillation. The paper analyzes the advantages, disadvantages, and potential solutions to the problems with each method and proposes a set of evaluation metrics for future research.>



---

