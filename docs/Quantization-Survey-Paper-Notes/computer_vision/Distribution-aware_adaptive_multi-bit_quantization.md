# Distribution-aware adaptive multi-bit quantization

## Summary

Summary: The paper presents a distribution-aware multi-bit quantization method (DMBQ) and loss-guided bit-width allocation (LBA) to compress deep neural networks by quantizing weights and activations into multi-bit binary networks (MBNs). The proposed method outperforms state-of-the-art quantized networks in terms of accuracy and is more efficient even for extremely low bit-width quantization cases.


## Target Task

computer vision

## Content

<Abstract: >In this paper, the authors propose a distribution-aware multi-bit quantization method (DMBQ) for compressing deep neural networks by quantizing the weights and activations into multi-bit binary networks (MBNs). They also propose loss-guided bit-width allocation (LBA) to adaptively prune and optimize neural networks. The experimental results show that their method outperforms state-of-the-art quantized networks in terms of accuracy and is more efficient in terms of training time, even for the extremely low bit-width quantization cases.



---

