# Few-Shot Zero-Shot Learning: Knowledge Transfer with Less Supervision

## Summary

Summary: The paper proposes a new setting for zero-shot learning called Few-Shot Zero-Shot Learning (FSZSL), where only a few annotated images are available from each seen class. They introduce a model that uses sparse attribute propagation (SAP) to propagate attribute annotations using sparse coding, followed by learning bidirectional projections between features and attributes for ZSL. The proposed model achieves state-of-the-art results.


## Target Task

computer vision

## Content

<Abstract: Existing zero-shot learning (ZSL) methods assume that there exist sufficient training samples from seen classes, each annotated with semantic descriptors such as attributes, for knowledge transfer to unseen classes without any training samples. However, in practice, it can be difficult to collect sufficient seen class samples and attribute annotation can be expensive. To address this issue, this paper proposes a new setting called Few-Shot Zero-Shot Learning (FSZSL), where only a few annotated images are collected from each seen class (i.e., few-shot). The proposed model uses sparse attribute propagation (SAP) to propagate attribute annotations to more unannotated images using sparse coding, followed by learning bidirectional projections between features and attributes for ZSL. The proposed model achieves state-of-the-art results.>



---

