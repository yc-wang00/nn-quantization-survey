# VC dimension of partially quantized neural networks in the overparametrized regime

## Summary

<Summary: >The paper discusses the effectiveness of hyperplane arrangement neural networks (HANNs) as partially quantized neural networks in terms of their Vapnik-Chervonenkis (VC) dimension and expressivity. The authors empirically demonstrate the performance of overparameterized HANNs on several datasets, showing that they can match the performance of full-precision models. Furthermore, they show that empirical risk minimization over HANNs achieves the minimax rate for classification with Lipschitz posterior class probability. Finally, the paper suggests future research directions related to overparameterized neural networks.


## Target Task

computer vision

## Content

<Abstract: >Using a sample compression analysis, this research paper explores a class of partially quantized neural networks called hyperplane arrangement neural networks (HANNs) and shows that they can have Vapnik-Chervonenkis (VC) dimension significantly smaller than the number of weights, while being highly expressive. The authors demonstrate the expressivity of HANNs empirically on a panel of 121 UCI datasets, where overparameterized HANNs match the performance of state-of-the-art full-precision models. The authors also show that empirical risk minimization over HANNs achieves the minimax rate for classification with Lipschitz posterior class probability. The paper highlights the generalization puzzle of overparameterized neural networks and suggests directions for future research.



---

