# IFQ-Net: Integrated fixed-point quantization networks for embedded vision

## Summary

Summary: The paper proposes a fixed-point network called Integrated Fixed-point Quantization Networks (IFQ-Net) for embedded vision tasks by converting floating-point data in a quantization network into fixed-point. The IFQ-Net gives significant savings on model size and runtime feature map memory with similar accuracy on ImageNet.


## Target Task

computer vision

## Content

<Abstract: Deploying deep models on embedded devices has been a challenging problem since the great success of deep learning based networks. Fixed-point networks, which represent their data with low bits fixed-point and thus give remarkable savings on memory usage, are generally preferred. Even though current fixed-point networks employ relative low bits ( e.g. 8-bits), the memory saving is far from enough for the embedded devices. In this paper, we propose a fixed-point network for embedded vision tasks through converting the floating-point data in a quantization network into fixed-point. We name the fixed-point network obtained through such integrated conversion as Integrated Fixed-point Quantization Networks (IFQ-Net). We demonstrate that our IFQ-Net gives 2.16 × and 18× more savings on model size and runtime feature map memory respectively with similar accuracy on ImageNet.>



---

