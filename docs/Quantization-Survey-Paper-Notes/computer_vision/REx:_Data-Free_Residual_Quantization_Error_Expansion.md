# REx: Data-Free Residual Quantization Error Expansion

## Summary

<Summary: >REx is a flexible quantization method that uses residual error expansion, group sparsity, and ensemble approximation to reduce the high inference cost of deep neural networks. It achieves superior performance on various applications, architectures, and bit-width. Unlike traditional quantization methods, REx provides multiple accuracy vs. speed trade-off points for each bit width. It outperforms data-free quantization algorithms and offers an interesting alternative to data-driven techniques in terms of accuracy.


## Target Task

computer vision

## Content

<Abstract: >Deep neural networks suffer from high inference cost, which can be addressed by quantization. We propose REx, a flexible quantization method that leverages residual error expansion, group sparsity and ensemble approximation for better parallelization. REx achieves superior performance on every benchmarked application, architecture and bit-width. Traditional quantization methods offer limited options for a specific target device, but REx provides multiple accuracy vs. speed trade-off points for each bit width. Data-free quantization algorithms were also published in recent years, but they still struggle to offer an interesting alternative to data-driven techniques in terms of accuracy.



---

