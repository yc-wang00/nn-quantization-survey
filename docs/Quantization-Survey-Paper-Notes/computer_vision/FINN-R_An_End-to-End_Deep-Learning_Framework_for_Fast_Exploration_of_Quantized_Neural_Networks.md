# FINN-R An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks

## Summary

<Summary: > This paper introduces the second generation of the FINN framework that is designed to automatically create customized inference engines for FPGAs. With reduced-precision representations, this framework optimizes neural networks for specific design targets and platforms to achieve numerical accuracy for various applications, resulting in unprecedented throughput.


## Target Task

computer vision

## Content

<Abstract: >Convolutional Neural Networks are highly successful in enabling machine vision and intelligent decision-making. However, the computational and memory requirements of these networks are challenging, and reduced-precision representations have been proposed as a promising solution. In this paper, we describe the second generation of the FINN framework, an end-to-end tool designed to automatically create customized inference engines for FPGAs. Using the tool, we demonstrate the optimization of reduced-precision neural networks on a range of platforms, including embedded devices, and achieve unprecedented throughput. The tool optimizes for specific design targets, platforms, and precision to achieve the required numerical accuracy for a given application.



---

