# PSAQ-ViT V2: Towards Accurate and General Data-Free Quantization for Vision Transformers

## Summary

<Summary: > PSAQ-ViT V2 is a data-free quantization framework proposed in this research paper for vision transformers, which uses an adaptive teacher-student strategy and patch similarity metric, and is compatible with a wide range of vision tasks and models, achieving competitive results without real-world data.


## Target Task

computer vision

## Content

<Abstract: > In this research paper, the authors propose a more accurate and general data-free quantization framework for vision transformers called PSAQ-ViT V2. It is built on top of patch similarity metric introduced in PSAQ-ViT and includes an adaptive teacher-student strategy which significantly improves the accuracy of the quantized model. The proposed scheme is compatible with a broad range of vision tasks and models without relying on auxiliary category guidance. The proposed approach is evaluated on various models on image classification, object detection, and semantic segmentation tasks, and consistently achieves competitive results without access to real-world data, showing potential as a powerful baseline on data-free quantization for ViTs.



---

