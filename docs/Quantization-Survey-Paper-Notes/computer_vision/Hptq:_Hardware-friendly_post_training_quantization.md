# Hptq: Hardware-friendly post training quantization

## Summary

Summary: This paper proposes a hardware-friendly post-training quantization framework for neural network quantization. The framework utilizes known quantization methods to meet the requirement for uniform, symmetric, and power-of-two quantizers for hardware efficiency. The proposed framework is evaluated on four computer vision tasks and shown to produce competitive results under hardware-friendly constraints.


## Target Task

computer vision

## Content

<Abstract:>
This paper introduces a hardware-friendly post-training quantization (HPTQ) framework for neural network quantization, which addresses the requirement for uniform, symmetric, and power-of-two quantizers for hardware efficiency. The framework combines several known quantization methods and is evaluated on four computer vision tasks. The experiments show that competitive results can be obtained under the hardware-friendly constraints.



---

