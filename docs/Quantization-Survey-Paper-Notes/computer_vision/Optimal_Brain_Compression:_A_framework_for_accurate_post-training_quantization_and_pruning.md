# Optimal Brain Compression: A framework for accurate post-training quantization and pruning

## Summary

<Summary: >The paper introduces a new framework for compression of deep neural networks that covers weight pruning and quantization in a unified setting. The approach is based on an efficient realization of the Optimal Brain Surgeon (OBS) framework and extends to cover weight quantization. The method improves upon the practical performance of existing post-training methods and enables the accurate compound application of both pruning and quantization in a post-training setting. The experimental results show significant improvements in the compression-accuracy trade-offs of existing methods.


## Target Task

computer vision

## Content

<Abstract: >We introduce a new compression framework for deep neural networks (DNNs) which covers both weight pruning and quantization in a uniﬁed setting, is time- and space-efﬁcient and considerably improves upon the practical performance of existing post-training methods. Our approach is based on an exact and efﬁcient realization of the classical Optimal Brain Surgeon (OBS) framework of [LeCun, Denker, and Solla, 1990] extended to also cover weight quantization at the scale of modern DNNs. Our experimental results show that it can significantly improve upon the compression-accuracy trade-offs of existing post-training methods, and that it can enable the accurate compound application of both pruning and quantization in a post-training setting.



---

