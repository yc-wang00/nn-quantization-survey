# Mirror descent view for neural network quantization

## Summary

<Summary: >The authors propose a Mirror Descent framework for neural network quantization that enables them to derive mirror maps and updates based on projections. They also present a numerically stable implementation of Mirror Descent that achieves state-of-the-art performance on CIFAR-10/100, TinyImageNet, and ImageNet classification datasets with VGG-16, ResNet-18, and MobileNetV2 architectures. Quantization is a technique for network compression that helps save memory and inference time by restricting the parameters to take values from a small discrete set.


## Target Task

computer vision

## Content

<Abstract: >In this research paper, the authors propose a Mirror Descent framework for neural network quantization, where quantization is a technique for network compression that restricts parameters to take values from a small discrete set, resulting in savings in memory and inference time. The authors introduce conditions on the projections that enable them to derive mirror maps and updates. They also present a numerically stable implementation of Mirror Descent, which yields state-of-the-art performance on CIFAR-10/100, TinyImageNet, and ImageNet classification datasets with VGG-16, ResNet-18, and MobileNetV2 architectures.



---

