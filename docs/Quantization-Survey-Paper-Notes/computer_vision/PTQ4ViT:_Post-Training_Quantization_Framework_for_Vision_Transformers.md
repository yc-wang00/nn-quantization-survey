# PTQ4ViT: Post-Training Quantization Framework for Vision Transformers

## Summary

<Summary: >This paper proposes the twin uniform quantization method and a Hessian guided metric to evaluate scaling factors in order to compress neural networks for vision transformers. They also develop an efficient framework called PTQ4ViT for fast quantization. Experimental results show near-lossless prediction accuracy achieved with less than 0.5% drop at 8-bit quantization on the ImageNet classification task.


## Target Task

computer vision

## Content

<Abstract: >Quantization is a powerful technique to compress neural networks, but previous post-training quantization methods did not perform well on vision transformers. In this paper, we propose the twin uniform quantization method to reduce the quantization error, and a Hessian guided metric to evaluate different scaling factors. We also develop an efficient framework, PTQ4ViT, that enables fast quantization of vision transformers. Experiments show that the quantized vision transformers achieve near-lossless prediction accuracy, with less than 0.5% drop at 8-bit quantization, on the ImageNet classification task.



---

