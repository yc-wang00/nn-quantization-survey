# Glide: Towards photorealistic image generation and editing with text-guided diffusion models

## Summary

Summary: The paper explores text-conditional image synthesis using diffusion models and compares two guidance strategies - CLIP guidance and classifier-free guidance. Human evaluators prefer the latter strategy for generating photorealistic and caption-similar samples. The models can also perform image inpainting, enabling powerful text-driven image editing. The code and weights for the smaller model have been released on Github.


## Target Task

computer vision

## Content

<Abstract: > Diffusion models can generate high-quality synthetic images when guided by a text-based technique to balance diversity and fidelity. In this paper, we explore text-conditional image synthesis using diffusion models and compare two guidance strategies: CLIP guidance and classifier-free guidance. Our human evaluators prefer the latter strategy for generating photorealistic and caption-similar samples. Furthermore, we demonstrate that our models can perform image inpainting, enabling powerful text-driven image editing. We release the code and weights for our smaller model at https://github.com/openai/glide-text2im.



---

