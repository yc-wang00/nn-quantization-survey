# Weighted-entropy-based quantization for deep neural networks

## Summary

<Summary: >This paper proposes a method for multi-bit quantization of neural network models based on weighted entropy. The proposed approach achieves significant reductions in model size and computation with minimal accuracy loss, while providing higher accuracy and requiring lower design effort compared to existing quantization schemes. The method allows for more flexible exploitation of accuracy-performance trade-off and provides an automated quantization flow based on conventional training algorithms.


## Target Task

computer vision

## Content

<Abstract: >Quantization is a method for optimizing the inference cost of neural network models for deployment to mobile and embedded systems with resource constraints. In this paper, we propose a method for quantizing weights and activations based on the concept of weighted entropy. Our approach is multi-bit quantization, which allows for more flexible exploitation of accuracy-performance trade-off. Our scheme provides automated quantization flow based on conventional training algorithms and achieves significant reductions in model size and computation with minimal accuracy loss. Compared to existing quantization schemes, ours provides higher accuracy with a similar resource constraint and requires much lower design effort.



---

