# Deep visual-semantic quantization for efficient image retrieval

## Summary

Summary: The paper proposes a method for efficient image retrieval through deep visual-semantic quantization (DVSQ). DVSQ is capable of learning deep quantization models from labeled image data and semantic information underlying general text domains. It uses hybrid networks and well-specified loss functions to jointly learn deep visual-semantic embeddings and visual-semantic quantizers. DVSQ is able to generate compact binary codes and achieve state-of-the-art similarity retrieval performance on standard benchmarks.


## Target Task

computer vision

## Content

<Abstract:>
This paper presents a solution for efficient image retrieval by end-to-end representation learning and compact encoding using deep visual-semantic quantization (DVSQ). DVSQ is the first approach to learning deep quantization models from labeled image data and semantic information underlying general text domains. It jointly learns deep visual-semantic embeddings and visual-semantic quantizers using hybrid networks and well-specified loss functions, enabling efficient and effective image retrieval by supporting maximum inner-product search. Comprehensive empirical evidence shows that DVSQ can generate compact binary codes and yield state-of-the-art similarity retrieval performance on standard benchmarks.



---

