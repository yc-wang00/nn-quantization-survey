# Illiterate dall-e learns to compose

## Summary

<Summary: >The paper proposes a slot-based autoencoding architecture called SLATE1 that combines the best of both worlds of DALL-E and object-centric representation models to systematically generalize for zero-shot generation of images without text. SLATE1 learns object-centric representations, enabling systematic generalization in zero-shot image generation without the need for a text prompt.


## Target Task

computer vision

## Content

<Abstract: > Although DALLE has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL E, its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE1, for combining the best of both worlds: learning object-centric representations that allows systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL E model.



---

