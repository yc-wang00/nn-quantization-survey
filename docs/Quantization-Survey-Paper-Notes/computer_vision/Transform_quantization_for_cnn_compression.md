# Transform quantization for cnn compression

## Summary

Summary: The paper proposes a post-training compression method using transform quantization to optimize and quantize CNN weights for better compression at a given quantization bit-rate. The method aims to unify quantization and dimensionality reduction using a rate-distortion framework. The experiments demonstrate that transform quantization improves the state of the art in CNN compression for both retrained and non-retrained scenarios.


## Target Task

computer vision

## Content

<Abstract: In this paper, we propose to compress convolutional neural network (CNN) weights post-training via transform quantization. We optimally transform (decorrelate) and quantize the weights post-training using a rateâ€“distortion framework to improve compression at any given quantization bit-rate. Transform quantization unifies quantization and dimensionality reduction (decorrelation) techniques in a single framework to facilitate low bit-rate compression of CNNs and efficient inference in the transform domain. Experiments demonstrate that transform quantization advances the state of the art in CNN compression in both retrained and non-retrained quantization scenarios.>



---

