# Binary neural networks: A survey

## Summary

Summary: This paper presents a comprehensive survey of algorithms used in binary neural networks. These algorithms are categorized into native solutions and optimized ones like minimizing the quantization error, improving the network loss function, and reducing the gradient error. The paper also investigates other practical aspects of binary neural networks and evaluates their performances on different tasks such as image classification, object detection, and semantic segmentation. Finally, the challenges that may be faced in future research are predicted.


## Target Task

computer vision

## Content

<Abstract: The binary neural network, largely saving the storage and computation, serves as a promising technique for deploying deep models on resource-limited devices. However, the binarization inevitably causes severe information loss, and even worse, its discontinuity brings difficulty to the optimization of the deep network. To address these issues, a variety of algorithms have been proposed, and achieved satisfying progress in recent years. In this paper, we present a comprehensive survey of these algorithms, mainly categorized into the native solutions directly conducting binarization, and the optimized ones using techniques like minimizing the quantization error, improving the network loss function, and reducing the gradient error. We also investigate other practical aspects of binary neural networks such as the hardware-friendly design and the training tricks. Then, we give the evaluation and discussions on different tasks, including image classification, object detection and semantic segmentation. Finally, the challenges that may be faced in future research are prospected. Keywords: binary neural network, deep learning, model compression, network quantization, model acceleration>



---

