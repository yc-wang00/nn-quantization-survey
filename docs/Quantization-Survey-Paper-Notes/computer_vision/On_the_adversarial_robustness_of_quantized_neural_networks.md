# On the adversarial robustness of quantized neural networks

## Summary

<Summary: >This paper explores the impact of quantization on the adversarial robustness of neural networks. The study found that quantization can improve or degrade adversarial robustness depending on the attack strength. This highlights the need to understand the trade-offs between model compression and robustness against adversarial attacks.


## Target Task

computer vision

## Content

<Abstract: >Reducing the size of neural network models is a critical step in moving AI from a cloud-centric to an edge-centric (i.e. on-device) compute paradigm. However, it is currently unclear how model compression techniques may affect the robustness of AI algorithms against adversarial attacks. This paper explores the effect of quantization, one of the most common compression techniques, on the adversarial robustness of neural networks. Results indicate that for simple gradient-based attacks, quantization can either improve or degrade adversarial robustness depending on the attack strength.



---

