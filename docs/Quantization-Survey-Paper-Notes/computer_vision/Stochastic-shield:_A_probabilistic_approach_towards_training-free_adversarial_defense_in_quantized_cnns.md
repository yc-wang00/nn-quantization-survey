# Stochastic-shield: A probabilistic approach towards training-free adversarial defense in quantized cnns

## Summary

<Summary: > The paper investigates how quantized neural networks are vulnerable to adversarial attacks and proposes a modular defense mechanism called Stochastic-Shield, which includes an input filtering layer and a Monte Carlo dropout approach, that can improve the efficiency and robustness of these models. The authors suggest that Stochastic-Shield can provide a feasible solution to real-world scenarios against attacks of varying strengths without retraining or fine-tuning.


## Target Task

computer vision

## Content

<Abstract:> In this research paper, the authors investigate the vulnerability of quantized neural networks to adversarial attacks and propose a probabilistic framework called Stochastic-Shield as a defense mechanism. The framework includes an input filtering layer and a Monte Carlo dropout approach. The authors show that this modular defense mechanism can improve the efficiency and robustness of quantized deep learning models without the need for retraining or fine-tuning. They also highlight the importance of providing robustness and adversarial defense to real-world scenarios against attacks of varying strengths. The authors propose Stochastic-Shield as a feasible solution to this challenge.



---

