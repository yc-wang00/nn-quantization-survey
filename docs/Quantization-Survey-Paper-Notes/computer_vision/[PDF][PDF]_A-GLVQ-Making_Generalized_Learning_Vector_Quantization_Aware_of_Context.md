# [PDF][PDF] A-GLVQ-Making Generalized Learning Vector Quantization Aware of Context

## Summary

<Summary: > This paper proposes a framework for adding context information to prototype generation in Generalized Learning Vector Quantization (GLVQ) models. The framework can model dependencies in a modular way using polynomials or neural networks. The evaluations on real-world and artificial datasets demonstrate improved performance and meaningful prototype adaptations.


## Target Task

computer vision

## Content

<Abstract: >Generalized Learning Vector Quantization (GLVQ) is a powerful and robust approach to classification tasks, but it has the disadvantage of prototypes not accounting for changes in the environment. In this paper, we propose a framework for incorporating context information into prototype generation that can model dependencies in a modular way ranging from polynomials to neural networks. The evaluations on artificial and real-world datasets show an increase in performance and meaningful prototype adaptations.



---

