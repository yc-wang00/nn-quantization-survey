# Leveraging noise and aggressive quantization of in-memory computing for robust dnn hardware against adversarial input and weight attacks

## Summary

Summary: The authors propose a new DNN training scheme that utilizes in-memory computing noise and partial sum quantization to improve the adversarial robustness of DNN hardware. They show that the noise induced by IMC can enhance DNN hardware robustness against adversarial attacks. The proposed scheme improves IMC DNN hardware robustness against black-box adversarial input attacks and bit-flip weight attacks, achieving up to 10.5% and 33.6% improvement, respectively. This study provides valuable insights for future research in this field.


## Target Task

computer vision

## Content

<Abstract: >In this research paper, the authors propose a new deep neural network (DNN) training scheme that takes advantage of in-memory computing (IMC) noise and partial sum quantization to improve the adversarial robustness of DNN hardware against both adversarial input and weight attacks. The authors discovered that the noise induced by IMC can play a positive role in enhancing the robustness of DNN hardware against adversarial attacks. The paper presents experimental results showing that the proposed scheme effectively improves the robustness of IMC DNN hardware against black-box adversarial input attacks and bit-flip weight attacks, achieving up to 10.5% (CIFAR-10 accuracy) and 33.6% (number of bit-flips) improvement compared to conventional DNNs. The proposed scheme evaluates the effect of IMC hardware noise and aggressive partial sum quantization at the IMC crossbar for both adversarial input and weight attacks, and the results provide valuable insights for future research in this field.



---

