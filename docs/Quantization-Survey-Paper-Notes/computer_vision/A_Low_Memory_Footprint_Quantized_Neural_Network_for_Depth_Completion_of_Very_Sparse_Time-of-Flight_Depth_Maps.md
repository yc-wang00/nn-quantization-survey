# A Low Memory Footprint Quantized Neural Network for Depth Completion of Very Sparse Time-of-Flight Depth Maps

## Summary

Summary: The paper proposes a quantized convolutional encoder-decoder network for depth completion, achieving optimal depth map quality through input pre-processing and carefully tuned training with a geometry-preserving loss function. The models are quantized using mixed precision quantization-at-training techniques, resulting in low memory footprint for weights and activations. The quantized models achieve significant reductions in GPU times and memory size with minimal impact on quality metrics.


## Target Task

computer vision

## Content

<Abstract:> We propose a quantized convolutional encoder-decoder network for depth completion of very sparse time-of-flight depth maps. Our model achieves optimal depth map quality by means of input pre-processing and carefully tuned training with a geometry-preserving loss function. We also achieve low memory footprint for weights and activations by means of mixed precision quantization-at-training techniques. The resulting quantized models are comparable to the state of the art in terms of quality, but they require very low GPU times and achieve up to 14-fold memory size reduction for the weights with minimal impact on quality metrics.



---

