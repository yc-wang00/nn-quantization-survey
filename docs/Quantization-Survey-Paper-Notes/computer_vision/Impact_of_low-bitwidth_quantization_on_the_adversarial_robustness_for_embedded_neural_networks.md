# Impact of low-bitwidth quantization on the adversarial robustness for embedded neural networks

## Summary

Summary: The article discusses the adversarial robustness of quantized neural networks for supervised image classification. The study found that weight quantization does not protect against adversarial attacks and can result in gradient masking. Poor transferability capacities were also observed due to quantization value shift and gradient misalignment. An ensemble-based defense method was suggested to address these issues.


## Target Task

computer vision

## Content

<Abstract: >
In this article, the authors investigate the adversarial robustness of quantized neural networks for a supervised image classification task. The authors show that weight quantization does not provide any robust protection against adversarial attacks and leads to severe gradient masking. The authors also explore hypotheses to explain these results. Finally, the authors experimentally observe poor transferability capacities which they explain by a quantization value shift phenomenon and gradient misalignment. The article also highlights an ensemble-based defense method to tackle these issues.



---

