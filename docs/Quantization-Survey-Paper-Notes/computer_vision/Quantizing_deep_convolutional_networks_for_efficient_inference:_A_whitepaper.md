# Quantizing deep convolutional networks for efficient inference: A whitepaper

## Summary

Summary: The paper presents a study on quantization methods for convolutional neural networks (CNNs), including their trade-offs and limitations. It describes different techniques to train CNNs for quantization and run-time constraints, provides guidelines on how to design and train efficient quantized CNNs with minimal loss in accuracy, and explains how to deploy them on neural network accelerators.


## Target Task

computer vision

## Content

<Abstract: >Quantization of weights and activations in deep neural networks can lead to reduced memory bandwidth requirements and lower power consumption during inference on hardware platforms. We present a study of quantization methods for convolutional neural networks (CNNs) which helps to understand their trade-offs and limitations. We describe these quantization methods for CNNs and quantify their effects on accuracy. We explore different techniques to train CNNs to accommodate quantization and run-time constraints. We also provide guidelines on how to design and train efficient quantized CNNs, with minimal loss in accuracy, and how to deploy them on neural network accelerators.



---

