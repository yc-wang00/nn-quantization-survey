# Video emotion recognition with transferred deep feature encodings

## Summary

<Summary: >This paper tackles the challenge of emotion understanding for user-generated videos by transferring deep feature encodings. It presents a framework for large-scale video emotion recognition, including zero-shot emotion recognition. The paper proposes a novel auxiliary Image Transfer Encoding (ITE) process to efficiently encode and generate video representation, and investigates different configurations of convolutional neural networks. Comprehensive experiments on multiple datasets demonstrate the effectiveness of the framework.


## Target Task

computer vision

## Content

<Abstract: >Despite growing research interest, emotion understanding for user-generated videos remains a challenging problem. Major obstacles include the diversity and complexity of video content, as well as the sparsity of expressed emotions. For the first time, we systematically study large-scale video emotion recognition by transferring deep feature encodings. In addition to the traditional, supervised recognition, we study the problem of zero-shot emotion recognition, where emotions in the test set are unseen during training. To cope with this task, we utilize knowledge transferred from auxiliary image and text corpora. A novel auxiliary Image Transfer Encoding (ITE) process is proposed to efficiently encode and generate video representation. We also thoroughly investigate different configurations of convolutional neural networks. Comprehensive experiments on multiple datasets demonstrate the effectiveness of our framework.



---

